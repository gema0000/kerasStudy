1주차 20181006
  1) 선형회귀, 가중치, y=wx+b 정의

2주차 20181013
  1) RNN, LSTM

3주차 20181020  
  1) activation, loss, optimizer 정의
  2) LSTM - stateful
  
4주차 20181027
  1) CNN
  2) 선형회귀, LSTM 다시 정리
  3) kaggle 스타트
  
5주차 20181104
  1) 다중입력, 다중출력
  2) 앙상블
  3) Embedding
  4) Conv1D
  5) BatchNormalization
  6) SeparableConv2D
  7) Kaggle 진행상태 점검
  8) 깃허브 

6주차 20181110 
  1) 1인창조 가입 完
  2) 캐글 제출방법 및 평가 실습
  3) 캐글 2sigma score가 1 이상인 이유 (혜림씨 개인 과제, 못하면 벌금 10억)
  4) 표준화, 정규화
  5) 카멜케이스
  6) activation, loss, optimizer 복습
  7) 깃허브 설정 및 실습
 
7주차 20181117
  1) 깃허브
  2) sklearn
    1. train_test_split
    2. Scaler
      - StandardScaler
      - MinmaxScler
    3. 각종기법 (사이킷런)   
      - Knn
      - ridge
      - lasso
      - logistic regression
      - Decision Tree
      - RandomForest
      - Gradient Boosting
      - SVM
      - MLP

8주차 20181124
  1) 깃허브 동기화
  2) 데이터 전처리
    train_test_split
    StandardScaler
    MinmaxScaler
    표준화, 정규화
  3) 사이킷런 전주 기법 반복.
  
9주차 20181202
  1) 전주차 복습 발표(shl)
  2) 1to1000 발표(jju)
  3) 1to1000 마무리  // 데이터 정규화 표준화부분. (이상치, 결측치 아직 안함)
  4) 사이킷런
    feature_importances_
    cross_val_score
    KFold
    GrodSearch
    GridSearchCV
    PipeLine
    
